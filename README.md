# JIRA Business Epic Analyzer and Reporter

A comprehensive tool that automates JIRA issue extraction, visualization, and reporting. This project scrapes JIRA issues, analyzes their relationships, generates visual representations, and creates HTML summaries enhanced by AI.

## ğŸ“‹ Features

- ğŸ” Automated JIRA login and issue extraction
- ğŸ”„ Recursive traversal of "is-realized-by" relationships and child issues
- ğŸ“Š Issue hierarchy visualization with GraphViz
- ğŸ¤– AI-powered business value extraction and summary generation
- ğŸ“ HTML report generation
- ğŸ“ˆ LLM token usage tracking and reporting

## ğŸ› ï¸ Technologies

- Python 3.10+
- Selenium for web scraping
- NetworkX and Matplotlib for graph visualization
- BeautifulSoup for HTML parsing
- LiteLLM/Anthropic Claude API for AI analysis
- Pandas for data processing

## ğŸ“ Repository Structure

```
business-epic-analyzer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ business_impact_api.py
â”‚   â”‚   â”œâ”€â”€ claude_api_integration.py
â”‚   â”‚   â”œâ”€â”€ cleanup_story_json.py
â”‚   â”‚   â”œâ”€â”€ data_extractor.py
â”‚   â”‚   â”œâ”€â”€ epic_html_generator.py
â”‚   â”‚   â”œâ”€â”€ file_exporter.py
â”‚   â”‚   â”œâ”€â”€ jira_tree_classes.py
â”‚   â”‚   â”œâ”€â”€ jira_scraper.py
â”‚   â”‚   â”œâ”€â”€ login_handler.py
â”‚   â”‚   â”œâ”€â”€ logger_config.py
â”‚   â”‚   â””â”€â”€ token_usage_class.py
â”‚   â””â”€â”€ main_scraper.py
â”œâ”€â”€ logs/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ html_reports/
â”‚   â”œâ”€â”€ issue_trees/
â”‚   â”œâ”€â”€ jira_issues/
â”‚   â””â”€â”€ json_summary/
â””â”€â”€ templates/
    â””â”€â”€ epic-html_template.html
```

## ğŸš€ Usage

1. Create a text file (`BE_Liste.txt`) with JIRA Business Epic keys (one per line):
```
BEMABU-1825
BEMABU-1844
```

2. Run the main script:
```bash
python src/main_scraper.py
```

3. The script will:
   - Log into JIRA with windows account credentials using chrome browser (not JIRA API)
   - Scrape data from each Business Epic and related issues
   - Generate visualization graphs
   - Create context files for AI processing
   - Generate AI summaries
   - Create HTML reports in the `data` directory

### Configuring Models

You can configure which AI models to use by modifying these variables in `main_scraper.py`:

```python
LLM_MODEL_HTML_GENERATOR = "gpt-4.1-mini"
LLM_MODEL_BUSINESS_VALUE = "claude-3-7-sonnet-latest"
LLM_MODEL_SUMMARY = "gpt-4.1"
```

## ğŸ“Š Output Files

The script generates several output files:

- `data/issue_trees/[EPIC-KEY]_issue_tree.png` - Visualization of issue relationships
- `data/json_summary/[EPIC-KEY]_json_summary.json` - AI-generated summary in JSON format
- `data/html_reports/[EPIC-KEY]_summary.html` - Final HTML report with embedded visualizations
